# -*- coding: utf-8 -*-
"""Artikel RPP_LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1phgHSbk7fnZjXnnZu-_zKlBmIlHh9CKO

**Kelompok 2 RPP**
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
import matplotlib.pyplot as plt

df = pd.read_csv('/content/btc_2015_2024.csv')
data = df.filter(['close'])
df['date'] = pd.to_datetime(df['date'])
df.set_index('date', inplace=True)

df.head()

dataset = data.values

scaler = MinMaxScaler(feature_range = (0,1))
scaled_data = scaler.fit_transform(dataset)

train_ratio = 0.8
training_data_len = int(np.round(train_ratio*len(dataset)))

lookback = 300
x_train, y_train = [], []

for i in range(lookback, len(scaled_data)):
  x_train.append(scaled_data[i-lookback:i, 0])
  y_train.append(scaled_data[i, 0])

x_train, y_train = np.array(x_train), np.array(y_train)

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

model = Sequential()
model.add(LSTM(50, return_sequences = True, input_shape = (x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences = False))
model.add(Dense(25))
model.add(Dense(1))

model.compile(optimizer = 'adam', loss = 'mean_squared_error')

history = model.fit(x_train, y_train, batch_size=32, epochs = 15, validation_split=0.2)

test_data = scaled_data[training_data_len - lookback:, :]

x_test = []
y_test = dataset[training_data_len:, :]
for i in range(lookback, len(test_data)):
  x_test.append(test_data[i-lookback:i, 0])

x_test = np.array(x_test)

x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

rmse = np.sqrt(np.mean(predictions - y_test)**2)
mae = np.mean(np.abs(predictions - y_test))
mape = np.mean(np.abs((predictions - y_test)/y_test))*100

print('RMSE:', rmse)
print('MAE:', mae)
print('MAPE:', mape)

train = df[:training_data_len]
valid = df[training_data_len:]
valid['Predictions'] = predictions

plt.figure(figsize = (16,8))
plt.title('Model')
plt.xlabel('date', fontsize = 18)
plt.ylabel('Close Price USD ($)', fontsize = 18)
plt.plot(train.index, train['close'])
plt.plot(valid.index, valid[['close', 'Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc = 'lower right')
plt.show()

"""# SISTEM PAKAR"""

model.save("bitcoin_prediction_model.h5")

import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler

# Fungsi prediksi
def predict_bitcoin_price(model_path, scaler, data, lookback=300):
    # Load model
    model = tf.keras.models.load_model(model_path)

    # Skalakan data input
    scaled_data = scaler.transform(data)

    # Siapkan data untuk prediksi
    x_input = []
    for i in range(lookback, len(scaled_data)):
        x_input.append(scaled_data[i-lookback:i, 0])

    x_input = np.array(x_input)
    x_input = np.reshape(x_input, (x_input.shape[0], x_input.shape[1], 1))

    # Prediksi
    predictions = model.predict(x_input)
    predictions = scaler.inverse_transform(predictions)
    return predictions

pip install streamlit

import streamlit as st
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
import numpy as np

# Load model dan scaler
model_path = "bitcoin_prediction_model.h5"
model = tf.keras.models.load_model(model_path)

# Fungsi prediksi
def predict_prices(data, lookback=300):
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)

    x_input = []
    for i in range(lookback, len(scaled_data)):
        x_input.append(scaled_data[i-lookback:i, 0])

    x_input = np.array(x_input)
    x_input = np.reshape(x_input, (x_input.shape[0], x_input.shape[1], 1))

    predictions = model.predict(x_input)
    return scaler.inverse_transform(predictions)

# Streamlit App
st.title("Bitcoin Price Prediction Expert System")
st.write("Upload a CSV file containing Bitcoin closing prices.")

uploaded_file = st.file_uploader("Choose a file", type=["csv"])
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    df['date'] = pd.to_datetime(df['date'])
    df.set_index('date', inplace=True)

    st.write("Dataset Preview:")
    st.write(df.head())

    # Prediksi
    st.write("Processing predictions...")
    predictions = predict_prices(df.filter(['close']).values)
    df['Predicted Prices'] = None
    df['Predicted Prices'][-len(predictions):] = predictions.flatten()

    st.write("Predictions:")
    st.line_chart(df[['close', 'Predicted Prices']])

!streamlit run app.py